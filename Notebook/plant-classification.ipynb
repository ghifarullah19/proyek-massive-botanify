{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8488203,"sourceType":"datasetVersion","datasetId":5063772},{"sourceId":8555653,"sourceType":"datasetVersion","datasetId":5112982},{"sourceId":8557595,"sourceType":"datasetVersion","datasetId":5112001}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install split-folders","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pip install tensorflow==2.12.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nprint(sys.version)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T05:52:54.209600Z","iopub.execute_input":"2024-06-01T05:52:54.210372Z","iopub.status.idle":"2024-06-01T05:52:54.234514Z","shell.execute_reply.started":"2024-06-01T05:52:54.210309Z","shell.execute_reply":"2024-06-01T05:52:54.233002Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0]\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T05:52:57.567820Z","iopub.execute_input":"2024-06-01T05:52:57.568819Z","iopub.status.idle":"2024-06-01T05:53:08.396635Z","shell.execute_reply.started":"2024-06-01T05:52:57.568773Z","shell.execute_reply":"2024-06-01T05:53:08.395153Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"2.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport os, splitfolders\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Input, Conv2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG19, VGG16, MobileNetV2\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-06-01T05:53:11.331036Z","iopub.execute_input":"2024-06-01T05:53:11.332697Z","iopub.status.idle":"2024-06-01T05:53:12.721976Z","shell.execute_reply.started":"2024-06-01T05:53:11.332627Z","shell.execute_reply":"2024-06-01T05:53:12.720622Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = (224, 224, 3)\nBATCH_SIZE = 32\nEPOCHS = 5\nNUM_CLASSES = 29","metadata":{"execution":{"iopub.status.busy":"2024-06-01T05:53:18.566390Z","iopub.execute_input":"2024-06-01T05:53:18.566894Z","iopub.status.idle":"2024-06-01T05:53:18.574671Z","shell.execute_reply.started":"2024-06-01T05:53:18.566857Z","shell.execute_reply":"2024-06-01T05:53:18.572875Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"splitfolders.ratio('/kaggle/input/raw-plant/botanify-360', output='/kaggle/working/tmp/plant-cv-images', seed=1337, ratio=(.6, .4))","metadata":{"execution":{"iopub.status.busy":"2024-06-01T05:53:21.758377Z","iopub.execute_input":"2024-06-01T05:53:21.758955Z","iopub.status.idle":"2024-06-01T05:54:44.823369Z","shell.execute_reply.started":"2024-06-01T05:53:21.758912Z","shell.execute_reply":"2024-06-01T05:54:44.822200Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Copying files: 10440 files [01:23, 125.73 files/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_plant_datagen = ImageDataGenerator(\n  rescale=1./255,\n  shear_range=0.2,\n  zoom_range=0.2,\n  fill_mode='nearest',\n)\n\ntest_plant_datagen = ImageDataGenerator(\n  rescale=1./255\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T05:54:46.541669Z","iopub.execute_input":"2024-06-01T05:54:46.542201Z","iopub.status.idle":"2024-06-01T05:54:46.549766Z","shell.execute_reply.started":"2024-06-01T05:54:46.542144Z","shell.execute_reply":"2024-06-01T05:54:46.548458Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_plant_generator = train_plant_datagen.flow_from_directory(\n  '/kaggle/working/tmp/plant-cv-images/train',\n  target_size=(IMAGE_SIZE[0], IMAGE_SIZE[1]),\n  batch_size=32,\n  class_mode='sparse'\n)\n\nvalidation_plant_generator = test_plant_datagen.flow_from_directory(\n  '/kaggle/working/tmp/plant-cv-images/val',\n  target_size=(IMAGE_SIZE[0], IMAGE_SIZE[1]),\n  batch_size=32,\n  class_mode='sparse'\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T05:54:49.968036Z","iopub.execute_input":"2024-06-01T05:54:49.968621Z","iopub.status.idle":"2024-06-01T05:54:50.418977Z","shell.execute_reply.started":"2024-06-01T05:54:49.968579Z","shell.execute_reply":"2024-06-01T05:54:50.417423Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 6264 images belonging to 29 classes.\nFound 4176 images belonging to 29 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"code","source":"# Create a callbacks\nclass CustomCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        if logs.get('accuracy') >= 0.95 and logs.get('val_accuracy') >= 0.95:\n            print(f'\\Training accuracy is higher than validation accuracy!')\n            self.model.stop_training = True\n\ncallbacks = CustomCallback()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T05:54:53.047493Z","iopub.execute_input":"2024-06-01T05:54:53.048100Z","iopub.status.idle":"2024-06-01T05:54:53.057674Z","shell.execute_reply.started":"2024-06-01T05:54:53.048050Z","shell.execute_reply":"2024-06-01T05:54:53.056326Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## CNN Model","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    ZeroPadding2D(padding=(2, 2), input_shape=IMAGE_SIZE),\n    Conv2D(16, (5, 5), strides=(1, 1), activation='relu'),\n    MaxPooling2D(2, 2),\n    Conv2D(32, (3, 3), strides=(1, 1), activation='relu'),\n    Conv2D(32, (3, 3), strides=(1, 1), activation='relu'),\n    MaxPooling2D(2, 2),\n    Conv2D(64, (3, 3), strides=(1, 1), activation='relu'),\n    Flatten(),\n    Dense(256, activation='relu'),\n    Dropout(0.5),\n    Dense(64, activation='relu'),\n    Dense(NUM_CLASSES, activation='softmax')\n])\n\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0001),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()\n\nhistory = model.fit(\n    train_plant_generator, \n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=validation_plant_generator,\n    callbacks=[callbacks]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('cnn_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(validation_plant_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## VGG16 Model","metadata":{}},{"cell_type":"code","source":"input_shape = IMAGE_SIZE\n\nvgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n\nfor layer in vgg16_base.layers:\n    layer.trainable = False\n\ninputs = Input(shape=input_shape)\nx = vgg16_base(inputs, training=False)\nx = Flatten()(x)\nx = Dense(256, activation='relu')(x)\noutputs = Dense(NUM_CLASSES, activation='softmax')(x)\n\nmodel_vgg16 = Model(inputs=inputs, outputs=outputs)\n\nmodel_vgg16.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nmodel_vgg16.summary()\n\nhistory_vgg16 = model_vgg16.fit(\n    train_plant_generator,\n    batch_size=BATCH_SIZE, \n    epochs=EPOCHS,\n    validation_data=(validation_plant_generator),\n    callbacks=[callbacks]\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T05:54:58.910999Z","iopub.execute_input":"2024-06-01T05:54:58.911510Z","iopub.status.idle":"2024-06-01T08:30:40.815527Z","shell.execute_reply.started":"2024-06-01T05:54:58.911472Z","shell.execute_reply":"2024-06-01T08:30:40.813893Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58889256/58889256 [==============================] - 0s 0us/step\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n dense (Dense)               (None, 256)               6422784   \n                                                                 \n dense_1 (Dense)             (None, 29)                7453      \n                                                                 \n=================================================================\nTotal params: 21,144,925\nTrainable params: 6,430,237\nNon-trainable params: 14,714,688\n_________________________________________________________________\nEpoch 1/5\n196/196 [==============================] - 3187s 16s/step - loss: 1.7049 - accuracy: 0.5364 - val_loss: 0.6180 - val_accuracy: 0.8326\nEpoch 2/5\n196/196 [==============================] - 3078s 16s/step - loss: 0.4188 - accuracy: 0.8967 - val_loss: 0.2805 - val_accuracy: 0.9231\nEpoch 3/5\n196/196 [==============================] - ETA: 0s - loss: 0.1743 - accuracy: 0.9646\\Training accuracy is higher than validation accuracy!\n196/196 [==============================] - 3075s 16s/step - loss: 0.1743 - accuracy: 0.9646 - val_loss: 0.1860 - val_accuracy: 0.9504\n","output_type":"stream"}]},{"cell_type":"code","source":"model_vgg16.save('botanify_model_vgg16.h5')","metadata":{"execution":{"iopub.status.busy":"2024-06-01T08:32:54.526129Z","iopub.execute_input":"2024-06-01T08:32:54.527438Z","iopub.status.idle":"2024-06-01T08:33:47.622484Z","shell.execute_reply.started":"2024-06-01T08:32:54.527322Z","shell.execute_reply":"2024-06-01T08:33:47.620943Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model_vgg16.evaluate(validation_plant_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## VGG19 Model","metadata":{}},{"cell_type":"code","source":"input_shape = IMAGE_SIZE\n\nvgg19_base = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n\nfor layer in vgg19_base.layers:\n    layer.trainable = False\n\ninputs = Input(shape=input_shape)\nx = vgg19_base(inputs, training=False)\nx = Flatten()(x)\nx = Dense(256, activation='relu')(x)\noutputs = Dense(NUM_CLASSES, activation='softmax')(x)\n\nmodel_vgg19 = Model(inputs=inputs, outputs=outputs)\n\nmodel_vgg19.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nmodel_vgg19.summary()\n\nhistory_vgg19 = model_vgg19.fit(\n    train_plant_generator,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=(validation_plant_generator),\n    callbacks=[callbacks]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_vgg19.save('model_vgg19.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_vgg19.evaluate(X_val, y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MobileNetV2 Model","metadata":{}},{"cell_type":"code","source":"input_shape = IMAGE_SIZE\n\nmobilenetv2_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n\nfor layer in mobilenetv2_base.layers:\n    layer.trainable = False\n\ninputs = Input(shape=input_shape)\nx = mobilenetv2_base(inputs, training=False)\nx = Flatten()(x)\nx = Dense(256, activation='relu')(x)\noutputs = Dense(NUM_CLASSES, activation='softmax')(x)\n\nmodel_mobilenetv2 = Model(inputs=inputs, outputs=outputs)\n\nmodel_mobilenetv2.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nmodel_mobilenetv2.summary()\n\nhistory_mobilenetv2 = model_mobilenetv2.fit(\n    train_plant_generator,\n    batch_size=BATCH_SIZE, \n    epochs=EPOCHS,\n    validation_data=(validation_plant_generator),\n    callbacks=[callbacks]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_mobilenetv2.save('model_mobilenetv2.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_mobilenetv2.evaluate(validation_plant_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"code","source":"class_names = os.listdir(train_folder)\nclass_names.sort()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot CNN","metadata":{}},{"cell_type":"code","source":"train_loss = history.history['accuracy']\nval_loss = history.history['val_accuracy']\n\nepochs = range(1, len(train_loss) + 1)\n\nplt.plot(epochs, train_loss, 'b-', label='Training Accuracy')  # Change 'bo' to 'b-'\nplt.plot(epochs, val_loss, 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(train_loss) + 1)\n\nplt.plot(epochs, train_loss, 'b-', label='Training Loss')  # Change 'bo' to 'b-'\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot VGG16","metadata":{}},{"cell_type":"code","source":"train_loss = history_vgg16.history['accuracy']\nval_loss = history_vgg16.history['val_accuracy']\n\nepochs = range(1, len(train_loss) + 1)\n\nplt.plot(epochs, train_loss, 'b-', label='Training Accuracy')  # Change 'bo' to 'b-'\nplt.plot(epochs, val_loss, 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss = history_vgg16.history['loss']\nval_loss = history_vgg16.history['val_loss']\n\nepochs = range(1, len(train_loss) + 1)\n\nplt.plot(epochs, train_loss, 'b-', label='Training Loss')  # Change 'bo' to 'b-'\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction CNN","metadata":{}},{"cell_type":"code","source":"# Mendapatkan prediksi untuk seluruh dataset validasi\ntest_predictions = model.predict(validation_plant_generator)\n\n# Mengambil class names dari validation_generator\nclass_to_index = {class_name: i for i, class_name in enumerate(class_names)}\nindex_to_class = {i: class_name for i, class_name in enumerate(class_names)}\n\n# Mengonversi prediksi ke kelas yang diprediksi\ntest_predictions_classes = np.argmax(test_predictions, axis=1)\ntest_predictions_class_names = [index_to_class[idx] for idx in test_predictions_classes]\n\n# Mengambil X_val dari validation_generator\nX_val = []\ny_val = []\n\n\nvalidation_plant_generator.reset()\nfor i in range(len(validation_plant_generator)):\n    X, y = next(validation_plant_generator)\n    X_val.append(X)\n    y_val.append(y)\n\nX_val = np.concatenate(X_val)\ny_val = np.concatenate(y_val)\n\n# Plotting hasil prediksi\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(X_val[i])\n    plt.title(\"Predicted: {}\".format(test_predictions_class_names[i]))\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion Matrix CNN","metadata":{}},{"cell_type":"code","source":"# Get true labels and predicted labels for validation data\ny_true_val = y_val\ny_pred_val = np.array([np.argmax(pred) for pred in model.predict(X_val)])\n\n# Compute confusion matrix\nconf_mat_val = confusion_matrix(y_true_val, y_pred_val)\n\n# Plot confusion matrix for validation data\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_mat_val, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix - Validation Data')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classification Report CNN","metadata":{}},{"cell_type":"code","source":"# Print classification report\nprint(\"Classification Report:\\n\", classification_report(y_true_val, y_pred_val, target_names=class_names))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction VGG16","metadata":{}},{"cell_type":"code","source":"test_predictions_vgg16 = model_vgg16.predict(validation_plant_generator)\nclass_to_index = {class_name: i for i, class_name in enumerate(class_names)}\nindex_to_class = {i: class_name for i, class_name in enumerate(class_names)}\ntest_predictions_classes_vgg16 = np.argmax(test_predictions_vgg16, axis=1)\ntest_predictions_class_names_vgg16 = [index_to_class[idx] for idx in test_predictions_classes_vgg16]\n\n# Mengambil X_val dari validation_generator\nX_val = []\ny_val = []\n\nvalidation_plant_generator.reset()\nfor i in range(len(validation_plant_generator)):\n    X, y = next(validation_plant_generator)\n    X_val.append(X)\n    y_val.append(y)\n\nX_val = np.concatenate(X_val)\ny_val = np.concatenate(y_val)\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(X_val[i])\n    plt.title(\"Predicted: {}\".format(test_predictions_class_names_vgg16[i]))\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion Matrix VGG16","metadata":{}},{"cell_type":"code","source":"# Get true labels and predicted labels for validation data\ny_true_val_vgg16 = y_val\ny_pred_val_vgg16 = np.array([np.argmax(pred) for pred in model_vgg16.predict(X_val)])\n\n# Compute confusion matrix\nconf_mat_val_vgg16 = confusion_matrix(y_true_val_vgg16, y_pred_val_vgg16)\n\n# Plot confusion matrix for validation data\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_mat_val_vgg16, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix - Validation Data')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classification Report VGG16","metadata":{}},{"cell_type":"code","source":"# Print classification report\nprint(\"Classification Report:\\n\", classification_report(y_true_val_vgg16, y_pred_val_vgg16, target_names=class_names))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot VGG19","metadata":{}},{"cell_type":"code","source":"train_loss = history_vgg19.history['accuracy']\nval_loss = history_vgg19.history['val_accuracy']\n\nepochs = range(1, len(train_loss) + 1)\n\nplt.plot(epochs, train_loss, 'b-', label='Training Accuracy')  # Change 'bo' to 'b-'\nplt.plot(epochs, val_loss, 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss = history_vgg19.history['loss']\nval_loss = history_vgg19.history['val_loss']\n\nepochs = range(1, len(train_loss) + 1)\n\nplt.plot(epochs, train_loss, 'b-', label='Training Loss')  # Change 'bo' to 'b-'\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction VGG19","metadata":{}},{"cell_type":"code","source":"test_predictions_vgg19 = model_vgg19.predict(validation_plant_generator)\nclass_to_index = {class_name: i for i, class_name in enumerate(class_names)}\nindex_to_class = {i: class_name for i, class_name in enumerate(class_names)}\ntest_predictions_classes_vgg19 = np.argmax(test_predictions_vgg19, axis=1)\ntest_predictions_class_names_vgg19 = [index_to_class[idx] for idx in test_predictions_classes_vgg19]\n\nX_val = []\ny_val = []\n\nvalidation_plant_generator.reset()\nfor i in range(len(validation_plant_generator)):\n    X, y = next(validation_plant_generator)\n    X_val.append(X)\n    y_val.append(y)\n\nX_val = np.concatenate(X_val)\ny_val = np.concatenate(y_val)\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(X_val[i])\n    plt.title(\"Predicted: {}\".format(test_predictions_class_names_vgg19[i]))\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion Matrix VGG19","metadata":{}},{"cell_type":"code","source":"# Get true labels and predicted labels for validation data\ny_true_val_vgg19 = y_val\ny_pred_val_vgg19 = np.array([np.argmax(pred) for pred in model_vgg19.predict(X_val)])\n\n# Compute confusion matrix\nconf_mat_val_vgg19 = confusion_matrix(y_true_val_vgg19, y_pred_val_vgg19)\n\n# Plot confusion matrix for validation data\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_mat_val_vgg19, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix - Validation Data')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classification Report VGG19","metadata":{}},{"cell_type":"code","source":"# Print classification report\nprint(\"Classification Report:\\n\", classification_report(y_true_val_vgg19, y_pred_val_vgg19, target_names=class_names))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot MobileNetV2","metadata":{}},{"cell_type":"code","source":"train_loss = history_mobilenetv2.history['accuracy']\nval_loss = history_mobilenetv2.history['val_accuracy']\n\nepochs = range(1, len(train_loss) + 1)\n\nplt.plot(epochs, train_loss, 'b-', label='Training Accuracy')  # Change 'bo' to 'b-'\nplt.plot(epochs, val_loss, 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss = history_mobilenetv2.history['loss']\nval_loss = history_mobilenetv2.history['val_loss']\n\nepochs = range(1, len(train_loss) + 1)\n\nplt.plot(epochs, train_loss, 'b-', label='Training Loss')  # Change 'bo' to 'b-'\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediciton MobileNetV2","metadata":{}},{"cell_type":"code","source":"# Predict class names for test data\ntest_predictions_mobilenetv2= model_mobilenetv2.predict(validation_plant_generator)\nclass_to_index = {class_name: i for i, class_name in enumerate(class_names)}\nindex_to_class = {i: class_name for i, class_name in enumerate(class_names)}\ntest_predictions_classes_mobilenetv2 = np.argmax(test_predictions_mobilenetv2, axis=1)\ntest_predictions_class_names_mobilenetv2 = [index_to_class[idx] for idx in test_predictions_classes_mobilenetv2]\n\nX_val = []\ny_val = []\n\nvalidation_plant_generator.reset()\nfor i in range(len(validation_plant_generator)):\n    X, y = next(validation_plant_generator)\n    X_val.append(X)\n    y_val.append(y)\n\nX_val = np.concatenate(X_val)\ny_val = np.concatenate(y_val)\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(X_val[i])\n    plt.title(\"Predicted: {}\".format(test_predictions_class_names_mobilenetv2[i]))\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion Matrix MobileNetV2","metadata":{}},{"cell_type":"code","source":"# Get true labels and predicted labels for validation data\ny_true_val_mobilenetv2 = y_val\ny_pred_val_mobilenetv2 = np.array([np.argmax(pred) for pred in model_mobilenetv2.predict(X_val)])\n\n# Compute confusion matrix\nconf_mat_val_mobilenetv2 = confusion_matrix(y_true_val_mobilenetv2, y_pred_val_mobilenetv2)\n\n# Plot confusion matrix for validation data\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_mat_val_mobilenetv2, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix - Validation Data')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classification Report MobileNetV2","metadata":{}},{"cell_type":"code","source":"# Print classification report\nprint(\"Classification Report:\\n\", classification_report(y_true_val_mobilenetv2, y_pred_val_mobilenetv2, target_names=class_names))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Unseen Data","metadata":{}},{"cell_type":"code","source":"test_folder = os.listdir('/kaggle/input/raw-data-again/unseen/unseen')\n\nscore_result = {} \n\ntotal_score = 0\ntotal_data = 0\n\nfor folder in test_folder:\n  score = 0\n  i = 0\n  plant = os.listdir(f'/kaggle/input/raw-data-again/unseen/unseen/{folder}')\n  # if folder == 'Tulip':\n  for uploaded in plant:\n    fn = f'/kaggle/input/raw-data-again/unseen/unseen/{folder}/{uploaded}'\n    # predicting images\n    path = fn\n    img = image.load_img(path, target_size=(150,150))\n\n    # imgplot = plt.imshow(img)\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    images = np.vstack([x])\n\n    classes = model.predict(images, batch_size=64)\n    out = np.argmax(classes)\n    # print(classes)\n    print(class_names[out])\n    \n    if class_names[out] == folder:\n      print(uploaded, folder)\n      score += 1\n    i += 1\n    total_data += 1\n  \n  total_score += score\n  score_result[folder] = f'{score}/{i}'\n\nprint(f\"Score Result: {score_result}\\n Total Score: {total_score}/{total_data} ({(total_score/total_data)*100}%)\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_folder = os.listdir('/kaggle/input/raw-data-again/unseen/unseen')\n\nscore_result = {} \n\ntotal_score = 0\ntotal_data = 0\n\nfor folder in test_folder:\n  score = 0\n  i = 0\n  plant = os.listdir(f'/kaggle/input/raw-data-again/unseen/unseen/{folder}')\n  # if folder == 'Tulip':\n  for uploaded in plant:\n    fn = f'/kaggle/input/raw-data-again/unseen/unseen/{folder}/{uploaded}'\n    # predicting images\n    path = fn\n    img = image.load_img(path, target_size=(100,100))\n\n    # imgplot = plt.imshow(img)\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    images = np.vstack([x])\n\n    classes = model_vgg16.predict(images, batch_size=64)\n    out = np.argmax(classes)\n    print(out)\n    print(class_names[out])\n    \n    if class_names[out] == folder:\n      print(uploaded, folder)\n      score += 1\n    i += 1\n    total_data += 1\n  \n  total_score += score\n  score_result[folder] = f'{score}/{i}'\n\nprint(f\"Score Result: {score_result}\\n Total Score: {total_score}/{total_data} ({(total_score/total_data)*100}%)\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_folder = os.listdir('/kaggle/input/raw-data-again/unseen/unseen')\n\nscore_result = {} \n\ntotal_score = 0\ntotal_data = 0\n\nfor folder in test_folder:\n  score = 0\n  i = 0\n  plant = os.listdir(f'/kaggle/input/raw-data-again/unseen/unseen/{folder}')\n  # if folder == 'Tulip':\n  for uploaded in plant:\n    fn = f'/kaggle/input/raw-data-again/unseen/unseen/{folder}/{uploaded}'\n    # predicting images\n    path = fn\n    img = image.load_img(path, target_size=(224,224))\n\n    # imgplot = plt.imshow(img)\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    images = np.vstack([x])\n\n    classes = model_vgg19.predict(images, batch_size=64)\n    out = np.argmax(classes)\n    # print(classes)\n    print(class_names[out])\n    \n    if class_names[out] == folder:\n      print(uploaded, folder)\n      score += 1\n    i += 1\n    total_data += 1\n  \n  total_score += score\n  score_result[folder] = f'{score}/{i}'\n\nprint(f\"Score Result: {score_result}\\n Total Score: {total_score}/{total_data} ({(total_score/total_data)*100}%)\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_folder = os.listdir('/kaggle/input/raw-data-again/unseen/unseen')\n\nscore_result = {} \n\ntotal_score = 0\ntotal_data = 0\n\nfor folder in test_folder:\n  score = 0\n  i = 0\n  plant = os.listdir(f'/kaggle/input/raw-data-again/unseen/unseen/{folder}')\n  # if folder == 'Tulip':\n  for uploaded in plant:\n    fn = f'/kaggle/input/raw-data-again/unseen/unseen/{folder}/{uploaded}'\n    # predicting images\n    path = fn\n    img = image.load_img(path, target_size=(224,224))\n\n    # imgplot = plt.imshow(img)\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    images = np.vstack([x])\n\n    classes = model_mobilenetv2.predict(images, batch_size=64)\n    out = np.argmax(classes)\n    # print(classes)\n    print(class_names[out])\n    \n    if class_names[out] == folder:\n      print(uploaded, folder)\n      score += 1\n    i += 1\n    total_data += 1\n  \n  total_score += score\n  score_result[folder] = f'{score}/{i}'\n\nprint(f\"Score Result: {score_result}\\n Total Score: {total_score}/{total_data} ({(total_score/total_data)*100}%)\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# write list train_folder to a txt file\nwith open('class_name.txt', 'w') as f:\n    for item in class_names:\n        f.write('\\'' + item + '\\'' + ', ')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}